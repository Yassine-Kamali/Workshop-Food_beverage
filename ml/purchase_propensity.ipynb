{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163e9823",
   "metadata": {},
   "source": [
    "# Purchase Propensity Model\n",
    "\n",
    "This notebook develops a model to predict customer purchase propensity based on demographic and behavioral features.\n",
    "\n",
    "## Objectives:\n",
    "- Predict likelihood of future purchases\n",
    "- Identify key drivers of purchase behavior\n",
    "- Segment customers by purchase potential\n",
    "- Provide targeting recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c188669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import snowflake.connector\n",
    "from snowflake.connector.pandas_tools import pd_read_sql\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954a795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Snowflake\n",
    "conn_params = {\n",
    "    'user': 'workshop_user',\n",
    "    'password': 'VotreMotDePasse123!',\n",
    "    'account': 'dnb65599.snowflakecomputing.com',\n",
    "    'warehouse': 'ANYCOMPANY_WH',\n",
    "    'database': 'ANYCOMPANY_LAB',\n",
    "    'schema': 'ANALYTICS'\n",
    "}\n",
    "\n",
    "conn = snowflake.connector.connect(**conn_params)\n",
    "print(\"Connected to Snowflake!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b18d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load customer data with synthetic target\n",
    "# Note: In real scenario, target would be based on actual purchase history\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    *,\n",
    "    -- Synthetic target: high propensity if high income and young age\n",
    "    CASE WHEN annual_income > 60000 AND age < 50 THEN 1 ELSE 0 END AS purchase_propensity\n",
    "FROM ANALYTICS.customer_ml_features\n",
    "\"\"\"\n",
    "\n",
    "df = pd_read_sql(query, conn)\n",
    "print(f\"Loaded {len(df)} customer records\")\n",
    "print(f\"Target distribution: {df['purchase_propensity'].value_counts(normalize=True)}\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf6199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "features = ['age', 'annual_income', 'age_group_encoded', 'income_segment_encoded',\n",
    "           'region_north', 'region_south', 'region_east', 'region_west']\n",
    "\n",
    "X = df[features]\n",
    "y = df['purchase_propensity']\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(f\"Selected features: {features}\")\n",
    "print(f\"Feature matrix shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba10da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f044e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model\n",
    "lr_model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression trained!\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_lr):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2367b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Random Forest trained!\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba_rf):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28f6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "models = ['Logistic Regression', 'Random Forest']\n",
    "predictions = [y_pred_lr, y_pred_rf]\n",
    "probabilities = [y_pred_proba_lr, y_pred_proba_rf]\n",
    "\n",
    "for name, pred, proba in zip(models, predictions, probabilities):\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(classification_report(y_test, pred))\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, proba):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d6762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for name, proba in zip(models, probabilities):\n",
    "    fpr, tpr, _ = roc_curve(y_test, proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Purchase Propensity Models')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94ffa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (Random Forest)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Feature Importance - Purchase Propensity')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top features driving purchase propensity:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74549399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate propensity scores for all customers\n",
    "df['propensity_score'] = rf_model.predict_proba(scaler.transform(df[features]))[:, 1]\n",
    "\n",
    "# Create propensity segments\n",
    "df['propensity_segment'] = pd.qcut(df['propensity_score'], q=4, labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "print(\"Propensity score distribution:\")\n",
    "print(df['propensity_segment'].value_counts().sort_index())\n",
    "\n",
    "# Visualize propensity distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='propensity_score', hue='propensity_segment', multiple='stack')\n",
    "plt.title('Customer Purchase Propensity Distribution')\n",
    "plt.xlabel('Propensity Score')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f259ae0a",
   "metadata": {},
   "source": [
    "## Business Recommendations\n",
    "\n",
    "### Key Insights:\n",
    "1. **Top Drivers**: Income and age are primary drivers of purchase propensity\n",
    "2. **High Propensity Segments**: Focus marketing efforts on high-propensity customers\n",
    "3. **Model Performance**: [ROC AUC scores]\n",
    "\n",
    "### Actionable Recommendations:\n",
    "1. **Targeted Marketing**: Prioritize high-propensity customers for campaigns\n",
    "2. **Personalization**: Tailor offers based on propensity scores\n",
    "3. **Retention Focus**: Develop retention strategies for high-propensity segments\n",
    "4. **Acquisition Strategy**: Target similar profiles for customer acquisition\n",
    "\n",
    "### Implementation:\n",
    "- Integrate propensity scores into CRM\n",
    "- Use scores for campaign targeting\n",
    "- Monitor score changes over time\n",
    "- Update model with new data quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ddf2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results\n",
    "results_df = df[['customer_id', 'propensity_score', 'propensity_segment']]\n",
    "print(f\"Results ready: {len(results_df)} customer propensity scores\")\n",
    "\n",
    "# Close connection\n",
    "conn.close()\n",
    "print(\"Purchase propensity analysis completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
