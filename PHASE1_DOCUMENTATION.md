# Phase 1 - Livrables & Documentation Technique

## ğŸ“‹ RÃ©sumÃ© de la Phase 1

Cette phase couvre la prÃ©paration et l'ingestion des donnÃ©es pour le projet AnyCompany Food & Beverage.

## âœ… Livrables complÃ©tÃ©s

### 1. Configuration de l'environnement Snowflake
- **Script:** [`01_setup_environment.sql`](sql/01_setup_environment.sql)
- **Objets crÃ©Ã©s:**
  - Database `ANYCOMPANY_LAB`
  - SchÃ©mas `BRONZE` et `SILVER`
  - Warehouse `ANYCOMPANY_WH` (XSMALL, auto-suspend 60s)
  - Stage externe S3 pointant vers `s3://logbrain-datalake/datasets/food-beverage/`
  - Formats de fichiers CSV et JSON

### 2. CrÃ©ation des tables BRONZE
- **Script:** [`02_create_bronze_tables.sql`](sql/02_create_bronze_tables.sql)
- **11 tables crÃ©Ã©es** pour recevoir les donnÃ©es brutes

### 3. Chargement des donnÃ©es
- **Script:** [`03_load_data.sql`](sql/03_load_data.sql)
- **MÃ©thode:** `COPY INTO` depuis stage S3
- **Traitement:**
  - 9 fichiers CSV chargÃ©s directement
  - 2 fichiers JSON chargÃ©s via tables temporaires avec parsing VARIANT

### 4. Nettoyage des donnÃ©es
- **Script:** [`04_clean_data.sql`](sql/04_clean_data.sql)
- **11 tables SILVER crÃ©Ã©es** avec suffixe `_clean`
- **Transformations appliquÃ©es:**
  - DÃ©doublonnage
  - Gestion des NULL
  - Standardisation des formats
  - Validation des valeurs
  - Colonnes calculÃ©es ajoutÃ©es

---

## ğŸ“Š DÃ©tail des tables

### Tables BRONZE (DonnÃ©es brutes)

| # | Table | Type source | Description | Colonnes clÃ©s |
|---|-------|-------------|-------------|---------------|
| 1 | `customer_demographics` | CSV | DÃ©mographie clients | customer_id, region, annual_income |
| 2 | `customer_service_interactions` | CSV | Interactions service client | interaction_id, customer_satisfaction |
| 3 | `financial_transactions` | CSV | Transactions financiÃ¨res | transaction_id, amount, region |
| 4 | `promotions_data` | CSV | Promotions commerciales | promotion_id, discount_percentage |
| 5 | `marketing_campaigns` | CSV | Campagnes marketing | campaign_id, budget, conversion_rate |
| 6 | `product_reviews` | CSV | Avis produits | review_id, rating, product_category |
| 7 | `inventory` | JSON | Niveaux de stock | product_id, current_stock, warehouse |
| 8 | `store_locations` | JSON | Localisations magasins | store_id, region, square_footage |
| 9 | `logistics_and_shipping` | CSV | DonnÃ©es logistiques | shipment_id, status, shipping_cost |
| 10 | `supplier_information` | CSV | Informations fournisseurs | supplier_id, reliability_score |
| 11 | `employee_records` | CSV | DonnÃ©es employÃ©s | employee_id, department, salary |

### Tables SILVER (DonnÃ©es nettoyÃ©es)

Chaque table BRONZE a une table correspondante dans SILVER avec le suffixe `_clean`.

**Exemple de transformations appliquÃ©es:**

#### `customer_demographics_clean`
- âœ… DÃ©doublonnage sur `customer_id`
- âœ… TRIM sur tous les champs texte
- âœ… Standardisation du genre (UPPER)
- âœ… Validation : `annual_income >= 0`

#### `financial_transactions_clean`
- âœ… DÃ©doublonnage sur `transaction_id`
- âœ… Conversion des montants en valeur absolue
- âœ… Standardisation des formats de date

#### `marketing_campaigns_clean`
- âœ… Calcul de `campaign_duration_days`
- âœ… Calcul de `cost_per_reach`
- âœ… Validation : `conversion_rate BETWEEN 0 AND 1`

#### `inventory_clean`
- âœ… Ajout du statut de stock : `Low Stock`, `Medium Stock`, `High Stock`
- âœ… DÃ©doublonnage par `product_id` et `warehouse`

---

## ğŸ” RÃ¨gles de qualitÃ© appliquÃ©es

### Gestion des doublons
```sql
QUALIFY ROW_NUMBER() OVER (PARTITION BY <id_column> ORDER BY <date_column> DESC) = 1
```

### Gestion des NULL
- Exclusion des enregistrements avec ID NULL
- Exclusion des dates NULL
- Conservation des NULL pour les champs optionnels

### Validation des valeurs
- Montants : `>= 0`
- Ratings : `BETWEEN 1 AND 5`
- Pourcentages : `BETWEEN 0 AND 1`
- Dates : `start_date <= end_date`

### Standardisation
- Texte : `TRIM()`, `UPPER()`, `LOWER()`
- Email : `LOWER(TRIM(email))`
- BoolÃ©ens : Conversion en `Yes`/`No`

---

## ğŸ“ˆ MÃ©triques de qualitÃ©

### VolumÃ©trie attendue

ExÃ©cuter pour obtenir les statistiques :
```sql
SELECT 
    table_schema,
    table_name,
    row_count
FROM INFORMATION_SCHEMA.TABLES
WHERE table_schema IN ('BRONZE', 'SILVER')
ORDER BY table_schema, table_name;
```

### Comparaison BRONZE vs SILVER

```sql
SELECT 
    'customer_demographics' AS table_name,
    (SELECT COUNT(*) FROM BRONZE.customer_demographics) AS bronze_count,
    (SELECT COUNT(*) FROM SILVER.customer_demographics_clean) AS silver_count,
    bronze_count - silver_count AS rows_removed
-- RÃ©pÃ©ter pour toutes les tables
```

---

## ğŸš¨ Points d'attention

### CrÃ©dits Snowflake
âš ï¸ **Attention Ã  la consommation de crÃ©dits !**
- Warehouse configurÃ© en XSMALL
- Auto-suspend aprÃ¨s 60 secondes d'inactivitÃ©
- Auto-resume activÃ© pour faciliter les tests

**Commande pour suspendre manuellement :**
```sql
ALTER WAREHOUSE ANYCOMPANY_WH SUSPEND;
```

### Erreurs potentielles

#### 1. Fichiers introuvables dans S3
```sql
-- VÃ©rifier la prÃ©sence des fichiers
LIST @ANYCOMPANY_LAB.BRONZE.S3_FOOD_BEVERAGE_STAGE;
```

#### 2. Erreurs de parsing CSV
- ParamÃ¨tre `ERROR_ON_COLUMN_COUNT_MISMATCH = FALSE` activÃ©
- ParamÃ¨tre `ON_ERROR = 'CONTINUE'` utilisÃ© dans COPY INTO

#### 3. Parsing JSON
- Utilisation de tables temporaires avec type `VARIANT`
- Casting explicite des types : `::VARCHAR`, `::INTEGER`, `::DATE`

---

## ğŸ¯ Validation finale

### Checklist de validation

- [ ] Database `ANYCOMPANY_LAB` crÃ©Ã©e
- [ ] SchÃ©mas `BRONZE` et `SILVER` crÃ©Ã©s
- [ ] 11 tables dans `BRONZE` avec donnÃ©es
- [ ] 11 tables dans `SILVER` avec donnÃ©es nettoyÃ©es
- [ ] Warehouse actif et accessible
- [ ] Stage S3 accessible
- [ ] Aucune erreur dans les logs

### RequÃªtes de validation

```sql
-- 1. Compter les tables par schÃ©ma
SELECT 
    table_schema,
    COUNT(*) AS table_count
FROM INFORMATION_SCHEMA.TABLES
WHERE table_schema IN ('BRONZE', 'SILVER')
GROUP BY table_schema;
-- Attendu : BRONZE = 11, SILVER = 11

-- 2. VÃ©rifier qu'aucune table n'est vide
SELECT 
    table_schema,
    table_name,
    row_count
FROM INFORMATION_SCHEMA.TABLES
WHERE table_schema IN ('BRONZE', 'SILVER')
  AND row_count = 0;
-- Attendu : Aucun rÃ©sultat

-- 3. Test d'exploration simple
SELECT 
    region,
    COUNT(*) AS customer_count
FROM SILVER.customer_demographics_clean
GROUP BY region
ORDER BY customer_count DESC
LIMIT 5;
```

---

## ğŸ“š Documentation complÃ©mentaire

### Commandes utiles

```sql
-- Se connecter au contexte
USE DATABASE ANYCOMPANY_LAB;
USE SCHEMA SILVER;
USE WAREHOUSE ANYCOMPANY_WH;

-- Explorer une table
DESCRIBE TABLE customer_demographics_clean;
SELECT * FROM customer_demographics_clean LIMIT 10;

-- Statistiques d'une colonne
SELECT 
    MIN(annual_income) AS min_income,
    MAX(annual_income) AS max_income,
    AVG(annual_income) AS avg_income
FROM customer_demographics_clean;

-- Ã‰chantillon alÃ©atoire
SELECT * FROM financial_transactions_clean SAMPLE (100 ROWS);
```

---

## ğŸ”— Ressources

- [Snowflake COPY INTO](https://docs.snowflake.com/en/sql-reference/sql/copy-into-table.html)
- [Snowflake Stages](https://docs.snowflake.com/en/user-guide/data-load-s3.html)
- [Snowflake JSON](https://docs.snowflake.com/en/user-guide/json-basics.html)
- [Snowflake Warehouses](https://docs.snowflake.com/en/user-guide/warehouses.html)

---

## ğŸ“ Prochaines Ã©tapes : Phase 2

La Phase 2 consistera Ã  :
1. Explorer les donnÃ©es SILVER
2. CrÃ©er des analyses SQL business
3. DÃ©velopper des dashboards Streamlit
4. Identifier les insights marketing

**Scripts Ã  crÃ©er pour la Phase 2 :**
- `sql/05_sales_analysis.sql`
- `sql/06_promotion_impact.sql`
- `sql/07_campaign_performance.sql`
- `streamlit/dashboard_sales.py`
- `streamlit/dashboard_marketing.py`

---

**Date :** Janvier 2026  
**Statut :** Phase 1 - âœ… ComplÃ©tÃ©e
